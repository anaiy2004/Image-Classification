{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.pynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anaiy2004/Image-Classification/blob/master/MNIST_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIOraAYvx3vj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is a model for image classification on MNIST data. Since MNIST data is generally simple to predict (black and white), using an MLP provides great results.\n",
        "# However, this same model would not perform very well for a more complex image classification dataset such as CIFAR-10\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF88KRjIx6_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128 \n",
        "num_classes = 10 \n",
        "epochs = 20"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgkqoVOTyQtV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9ea88d80-1d31-492a-9c8c-f668e5475385"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC0r7BenzT18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHPtp2FezYbS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "a0cab3ae-3169-4991-8809-d01a20839a5b"
      },
      "source": [
        "model = Sequential() \n",
        "model.add(Dense(128, activation='relu', input_shape=(784,)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                170       \n",
            "=================================================================\n",
            "Total params: 109,946\n",
            "Trainable params: 109,946\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIQ6zOFxzo3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=\"Adam\",\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMjbwVhizuwl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "156af091-6db5-401d-9c67-8627f168f252"
      },
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs= epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0469 - accuracy: 0.9856 - val_loss: 0.0791 - val_accuracy: 0.9757\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0410 - accuracy: 0.9873 - val_loss: 0.0938 - val_accuracy: 0.9731\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0330 - accuracy: 0.9895 - val_loss: 0.0777 - val_accuracy: 0.9768\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0270 - accuracy: 0.9918 - val_loss: 0.0884 - val_accuracy: 0.9752\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0223 - accuracy: 0.9929 - val_loss: 0.0932 - val_accuracy: 0.9758\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0207 - accuracy: 0.9934 - val_loss: 0.1020 - val_accuracy: 0.9737\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0173 - accuracy: 0.9946 - val_loss: 0.0903 - val_accuracy: 0.9780\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.0963 - val_accuracy: 0.9764\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 0.1144 - val_accuracy: 0.9724\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.1068 - val_accuracy: 0.9769\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.1256 - val_accuracy: 0.9730\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 0.1059 - val_accuracy: 0.9774\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.1074 - val_accuracy: 0.9759\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.1067 - val_accuracy: 0.9791\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.1073 - val_accuracy: 0.9786\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1062 - val_accuracy: 0.9791\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.1172 - val_accuracy: 0.9760\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.1222 - val_accuracy: 0.9759\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.1125 - val_accuracy: 0.9762\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 0.1260 - val_accuracy: 0.9757\n",
            "Test loss: 0.1259892687629918\n",
            "Test accuracy: 0.9757000207901001\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}